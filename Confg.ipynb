{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from confgf import models, dataset, runner, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "\n",
    "from confgf import utils, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = 'C:\\\\Users\\\\hp\\\\alearn\\\\ICML_conformation\\\\small_dataset_appendix\\\\small_dataset_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_set = 'val_data_0k.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(load_path, val_set),'rb') as fin:\n",
    "    val_data = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = None \n",
    "val_data = dataset.GEOMDataset(data=val_data, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_path = 'C:\\\\Users\\\\hp\\\\alearn\\\\ICML_conformation\\\\ConfGF-main\\\\config\\\\drugs_default.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config = EasyDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DistanceScoreMatch_(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(DistanceScoreMatch_, self).__init__()\n",
    "        self.config = config\n",
    "        self.anneal_power = self.config.train.anneal_power\n",
    "        self.hidden_dim = self.config.model.hidden_dim\n",
    "        self.order = self.config.model.order\n",
    "        self.noise_type = self.config.model.noise_type\n",
    "        self.node_emb = torch.nn.Embedding(100, self.hidden_dim)\n",
    "        self.edge_emb = torch.nn.Embedding(100, self.hidden_dim)\n",
    "        self.input_mlp = layers.MultiLayerPerceptron(1, [self.hidden_dim, self.hidden_dim], activation=self.config.model.mlp_act)\n",
    "        self.output_mlp = layers.MultiLayerPerceptron(2 * self.hidden_dim, \\\n",
    "                                [self.hidden_dim, self.hidden_dim // 2, 1], activation=self.config.model.mlp_act)\n",
    "\n",
    "        self.model = layers.GraphIsomorphismNetwork(hidden_dim=self.hidden_dim, \\\n",
    "                                 num_convs=self.config.model.num_convs, \\\n",
    "                                 activation=self.config.model.gnn_act, \\\n",
    "                                 readout=\"sum\", short_cut=self.config.model.short_cut, \\\n",
    "                                 concat_hidden=self.config.model.concat_hidden)\n",
    "        sigmas = torch.tensor(\n",
    "            np.exp(np.linspace(np.log(self.config.model.sigma_begin), np.log(self.config.model.sigma_end),\n",
    "                               self.config.model.num_noise_level)), dtype=torch.float32)\n",
    "        self.sigmas = nn.Parameter(sigmas, requires_grad=False) # (num_noise_level)\n",
    "\n",
    "        \"\"\"\n",
    "        Techniques from \"Improved Techniques for Training Score-Based Generative Models\"\n",
    "        1. Choose sigma1 to be as large as the maximum Euclidean distance between all pairs of training data points.\n",
    "        2. Choose sigmas as a geometric progression with common ratio gamma, where a specific equation of CDF is satisfied.\n",
    "        3. Parameterize the Noise Conditional Score Networks with f_theta_sigma(x) =  f_theta(x) / sigma\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    # extend the edge on the fly, second order: angle, third order: dihedral\n",
    "    def extend_graph(self, data: Data, order=3):\n",
    "\n",
    "        def binarize(x):\n",
    "            return torch.where(x > 0, torch.ones_like(x), torch.zeros_like(x))\n",
    "\n",
    "        def get_higher_order_adj_matrix(adj, order):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                adj:        (N, N)\n",
    "                type_mat:   (N, N)\n",
    "            \"\"\"\n",
    "            adj_mats = [torch.eye(adj.size(0), dtype=torch.long, device=adj.device), \\\n",
    "                        binarize(adj + torch.eye(adj.size(0), dtype=torch.long, device=adj.device))]\n",
    "\n",
    "            for i in range(2, order+1):\n",
    "                adj_mats.append(binarize(adj_mats[i-1] @ adj_mats[1]))\n",
    "            order_mat = torch.zeros_like(adj)\n",
    "\n",
    "            for i in range(1, order+1):\n",
    "                order_mat += (adj_mats[i] - adj_mats[i-1]) * i\n",
    "\n",
    "            return order_mat\n",
    "\n",
    "        num_types = len(utils.BOND_TYPES)\n",
    "\n",
    "        N = data.num_nodes\n",
    "        adj = to_dense_adj(data.edge_index).squeeze(0)\n",
    "        adj_order = get_higher_order_adj_matrix(adj, order)  # (N, N)\n",
    "\n",
    "        type_mat = to_dense_adj(data.edge_index, edge_attr=data.edge_type).squeeze(0)   # (N, N)\n",
    "        type_highorder = torch.where(adj_order > 1, num_types + adj_order - 1, torch.zeros_like(adj_order))\n",
    "        assert (type_mat * type_highorder == 0).all()\n",
    "        type_new = type_mat + type_highorder\n",
    "\n",
    "        new_edge_index, new_edge_type = dense_to_sparse(type_new)\n",
    "        _, edge_order = dense_to_sparse(adj_order)\n",
    "\n",
    "        data.bond_edge_index = data.edge_index  # Save original edges\n",
    "        data.edge_index, data.edge_type = coalesce(new_edge_index, new_edge_type.long(), N, N) # modify data\n",
    "        edge_index_1, data.edge_order = coalesce(new_edge_index, edge_order.long(), N, N) # modify data\n",
    "        data.is_bond = (data.edge_type < num_types)\n",
    "        assert (data.edge_index == edge_index_1).all()\n",
    "\n",
    "        return data\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_distance(self, data: Data):\n",
    "        pos = data.pos\n",
    "        row, col = data.edge_index\n",
    "        d = (pos[row] - pos[col]).norm(dim=-1).unsqueeze(-1) # (num_edge, 1)\n",
    "        data.edge_length = d\n",
    "        return data   \n",
    "      \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_score(self, data: Data, d, sigma):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            data: torch geometric batched data object\n",
    "            d: edge distance, shape (num_edge, 1)\n",
    "            sigma: noise level, tensor (,)\n",
    "        Output:\n",
    "            log-likelihood gradient of distance, tensor with shape (num_edge, 1)         \n",
    "        \"\"\"\n",
    "        node_attr = self.node_emb(data.atom_type) # (num_node, hidden)\n",
    "        edge_attr = self.edge_emb(data.edge_type) # (num_edge, hidden)      \n",
    "        d_emb = self.input_mlp(d) # (num_edge, hidden)\n",
    "        edge_attr = d_emb * edge_attr # (num_edge, hidden)\n",
    "        print('data.shape',data.shape)\n",
    "        output = self.model(data, node_attr, edge_attr)\n",
    "        h_row, h_col = output[\"node_feature\"][data.edge_index[0]], output[\"node_feature\"][data.edge_index[1]] # (num_edge, hidden)\n",
    "        distance_feature = torch.cat([h_row*h_col, edge_attr], dim=-1) # (num_edge, 2 * hidden)\n",
    "        scores = self.output_mlp(distance_feature) # (num_edge, 1)\n",
    "        scores = scores * (1. / sigma) # f_theta_sigma(x) =  f_theta(x) / sigma, (num_edge, 1)\n",
    "        return scores\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            data: torch geometric batched data object\n",
    "        Output:\n",
    "            loss\n",
    "        \"\"\"\n",
    "        # a workaround to get the current device, we assume all tensors in a model are on the same device.\n",
    "        self.device = self.sigmas.device\n",
    "        print('extend前的data',data)\n",
    "        print()\n",
    "        data = self.extend_graph(data, self.order)\n",
    "        print('extended_data',data)\n",
    "        print()\n",
    "        data = self.get_distance(data)\n",
    "        print('get_distance_data',data)\n",
    "        global get_distance_data_test\n",
    "        get_distance_data_test = data\n",
    "        print()\n",
    "\n",
    "        assert data.edge_index.size(1) == data.edge_length.size(0)\n",
    "        print('data.batch',data.batch)\n",
    "        node2graph = data.batch\n",
    "        edge2graph = node2graph[data.edge_index[0]]        \n",
    "\n",
    "        # sample noise level\n",
    "        noise_level = torch.randint(0, self.sigmas.size(0), (data.num_graphs,), device=self.device) # (num_graph)\n",
    "        used_sigmas = self.sigmas[noise_level] # (num_graph)\n",
    "        used_sigmas = used_sigmas[edge2graph].unsqueeze(-1) # (num_edge, 1)\n",
    "\n",
    "        # perturb\n",
    "        d = data.edge_length # (num_edge, 1)\n",
    "        #\n",
    "        global d_test\n",
    "        d_test = d\n",
    "        print('d',d)\n",
    "        #\n",
    "        \n",
    "        if self.noise_type == 'symmetry':\n",
    "            num_nodes = scatter_add(torch.ones(data.num_nodes, dtype=torch.long, device=self.device), node2graph) # (num_graph)\n",
    "            num_cum_nodes = num_nodes.cumsum(0) # (num_graph)\n",
    "            node_offset = num_cum_nodes - num_nodes # (num_graph)\n",
    "            edge_offset = node_offset[edge2graph] # (num_edge)\n",
    "\n",
    "            num_nodes_square = num_nodes**2 # (num_graph)\n",
    "            num_nodes_square_cumsum = num_nodes_square.cumsum(-1) # (num_graph)\n",
    "            edge_start = num_nodes_square_cumsum - num_nodes_square # (num_graph)\n",
    "            edge_start = edge_start[edge2graph]\n",
    "\n",
    "            all_len = num_nodes_square_cumsum[-1]\n",
    "\n",
    "            node_index = data.edge_index.t() - edge_offset.unsqueeze(-1)\n",
    "            #node_in, node_out = node_index.t()\n",
    "            node_large = node_index.max(dim=-1)[0]\n",
    "            node_small = node_index.min(dim=-1)[0]\n",
    "            undirected_edge_id = node_large * (node_large + 1) + node_small + edge_start\n",
    "\n",
    "            symm_noise = torch.FloatTensor(all_len, device=self.device).normal_()\n",
    "            d_noise = symm_noise[undirected_edge_id].unsqueeze(-1) # (num_edge, 1)\n",
    "\n",
    "        elif self.noise_type == 'rand':\n",
    "            d_noise = torch.randn_like(d)\n",
    "        else:\n",
    "            raise NotImplementedError('noise type must in [distance_symm, distance_rand]')\n",
    "        assert d_noise.shape == d.shape\n",
    "        perturbed_d = d + d_noise * used_sigmas \n",
    "        #\n",
    "        print('perturbed_d',perturbed_d)\n",
    "        global perturbed_d_test\n",
    "        perturbed_d_test = perturbed_d\n",
    "        #\n",
    "        #perturbed_d = torch.clamp(perturbed_d, min=0.1, max=float('inf'))    # distances must be greater than 0\n",
    "\n",
    "\n",
    "\n",
    "        # get target, origin_d minus perturbed_d\n",
    "        target = -1 / (used_sigmas ** 2) * (perturbed_d - d) # (num_edge, 1)\n",
    "\n",
    "        # estimate scores\n",
    "        node_attr = self.node_emb(data.atom_type) # (num_node, hidden)\n",
    "        edge_attr = self.edge_emb(data.edge_type) # (num_edge, hidden)\n",
    "        d_emb = self.input_mlp(perturbed_d) # (num_edge, hidden)\n",
    "        edge_attr = d_emb * edge_attr # (num_edge, hidden)\n",
    "        print('Attention!',data.shape)\n",
    "        output = self.model(data, node_attr, edge_attr)\n",
    "        h_row, h_col = output[\"node_feature\"][data.edge_index[0]], output[\"node_feature\"][data.edge_index[1]] # (num_edge, hidden)\n",
    "\n",
    "        distance_feature = torch.cat([h_row*h_col, edge_attr], dim=-1) # (num_edge, 2 * hidden)\n",
    "        scores = self.output_mlp(distance_feature) # (num_edge, 1)\n",
    "        scores = scores * (1. / used_sigmas) # f_theta_sigma(x) =  f_theta(x) / sigma, (num_edge, 1)\n",
    "\n",
    "        target = target.view(-1) # (num_edge)\n",
    "        scores = scores.view(-1) # (num_edge)\n",
    "        loss =  0.5 * ((scores - target) ** 2) * (used_sigmas.squeeze(-1) ** self.anneal_power) # (num_edge)\n",
    "        loss = scatter_add(loss, edge2graph) # (num_graph)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13110, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.edge_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DistanceScoreMatch_(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "from torch_scatter import scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEOMDataset(2500)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(val_data, batch_size=10,\n",
    "                                shuffle=False, num_workers=config.train.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x1f1dcd8a588>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 1\n",
    "for batch in dataloader:\n",
    "    if flag == 1:\n",
    "        flag+=1\n",
    "        test = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(edge_index=[2, 2530], pos=[1220, 3], atom_type=[1220], edge_type=[2530], rdmol=[10], smiles=[10], totalenergy=[10], boltzmannweight=[10], idx=[10], batch=[1220], ptr=[11])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extend前的data Batch(edge_index=[2, 2530], pos=[1220, 3], atom_type=[1220], edge_type=[2530], rdmol=[10], smiles=[10], totalenergy=[10], boltzmannweight=[10], idx=[10], batch=[1220], ptr=[11])\n",
      "\n",
      "extended_data Batch(edge_index=[2, 13110], pos=[1220, 3], atom_type=[1220], edge_type=[13110], rdmol=[10], smiles=[10], totalenergy=[10], boltzmannweight=[10], idx=[10], batch=[1220], ptr=[11], bond_edge_index=[2, 2530], edge_order=[13110], is_bond=[13110])\n",
      "\n",
      "get_distance_data Batch(edge_index=[2, 13110], pos=[1220, 3], atom_type=[1220], edge_type=[13110], rdmol=[10], smiles=[10], totalenergy=[10], boltzmannweight=[10], idx=[10], batch=[1220], ptr=[11], bond_edge_index=[2, 2530], edge_order=[13110], is_bond=[13110], edge_length=[13110, 1])\n",
      "\n",
      "data.batch tensor([0, 0, 0,  ..., 9, 9, 9])\n",
      "d tensor([[1.1972],\n",
      "        [2.6511],\n",
      "        [3.2047],\n",
      "        ...,\n",
      "        [1.0496],\n",
      "        [2.2467],\n",
      "        [3.7015]])\n",
      "perturbed_d tensor([[ 1.1888],\n",
      "        [ 2.6611],\n",
      "        [ 3.2271],\n",
      "        ...,\n",
      "        [ 1.3624],\n",
      "        [-3.2662],\n",
      "        [ 3.0456]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4467e+16, 1.4420e+16, 1.8706e+16, 1.4466e+16, 1.4434e+16, 6.5989e+15,\n",
       "        6.5989e+15, 6.5981e+15, 9.8038e+15, 6.7781e+15],\n",
       "       grad_fn=<ScatterAddBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5870])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.edge_type.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = config.model.hidden_dim\n",
    "input_mlp = layers.MultiLayerPerceptron(1, [config.model.hidden_dim, config.model.hidden_dim], activation=config.model.mlp_act)\n",
    "node_emb = torch.nn.Embedding(100, config.model.hidden_dim)\n",
    "edge_emb = torch.nn.Embedding(100, config.model.hidden_dim)\n",
    "GNN_model = layers.GraphIsomorphismNetwork(hidden_dim=hidden_dim, \\\n",
    "                                 num_convs=config.model.num_convs, \\\n",
    "                                 activation=config.model.gnn_act, \\\n",
    "                                 readout=\"sum\", short_cut=config.model.short_cut, \\\n",
    "                                 concat_hidden=config.model.concat_hidden)\n",
    "output_mlp = layers.MultiLayerPerceptron(2 * hidden_dim, \\\n",
    "                                [hidden_dim, hidden_dim // 2, 1], activation=config.model.mlp_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_attr = node_emb(get_distance_data_test.atom_type)\n",
    "edge_attr = edge_emb(get_distance_data_test.edge_type)\n",
    "d_emb = input_mlp(perturbed_d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr_shape torch.Size([5870, 256])\n",
      "d_emb_shape torch.Size([5870, 256])\n"
     ]
    }
   ],
   "source": [
    "print('edge_attr_shape',edge_attr.shape)\n",
    "print('d_emb_shape',d_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr_shape torch.Size([5870, 256])\n"
     ]
    }
   ],
   "source": [
    "edge_attr = d_emb * edge_attr\n",
    "print('edge_attr_shape',edge_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = get_distance_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = GNN_model(get_distance_data_test, node_attr, edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_row, h_col = output[\"node_feature\"][data.edge_index[0]], output[\"node_feature\"][data.edge_index[1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5870, 256])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5870, 256])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_col.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance_feature = torch.cat([h_row*h_col, edge_attr], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = output_mlp(distance_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  376595.0625],\n",
       "        [  233812.0469],\n",
       "        [  582789.6250],\n",
       "        ...,\n",
       "        [10608018.0000],\n",
       "        [10608020.0000],\n",
       "        [ 4998975.5000]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
